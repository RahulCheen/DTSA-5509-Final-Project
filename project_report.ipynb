{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTSA 5509 Final Project\n",
    "## Predicting Walkability of U.S. Counties\n",
    "\n",
    "#### Rahul Cheeniyil\n",
    "#### 12-11-2024\n",
    "\n",
    "In this project, I use the Walkability Index dataset ([published by the U.S. Environmental Protection Agency](https://catalog.data.gov/dataset/walkability-index7)) to build and test supervised learning models to predict walkability of U.S. Census Blocks. Predicting walkability is important for allocating infrastructure funding for areas with low pedestrian accessibility. Improving city walkability can promote for public health and safety as well as reduce automobile traffic and improve environmental health due to reduced emissions.\n",
    "\n",
    "The models I will use are multilinear regression and gradient boosting. In this report, I will walk through the data I use, how I intend to use it, data cleaning, and exploratory data analysis prior to building the models themselves. Model performance will be assessed at the end of the report.\n",
    "\n",
    "### Data\n",
    "The data consists of various metrics from Censis 2019 block groups. The data is accessed by a publicly available API. The code cell below loads the data via REST API requests and loads it into a Pandas DataFrame. The resulting DataFrame has 220,134 rows and 182 columns. Each row corresponds to a U.S. Census Block and each column responds to a metric associated with that block. The column \"NatWalkInd\" is the National Walkability Index score assigned to the block. This is the metric I will be predicting with machine learning models. All other columns reflect various metrics/statistics associated with the block. These 181 columns can be grouped into several categories.\n",
    "- Geographic Identifiers: Spatial and administrative context for identifying the blocks\n",
    "- Population and Demographics: Population of the block and various demographic distributions.\n",
    "- Automobile Ownership Statistics: Car ownership/dependency of residents including percentage of households owning different numbers of vehicles.\n",
    "- Employment and Wages: Job distributions and wage levels.\n",
    "- Land Use and Density: Metrics related to the land itself.\n",
    "- Transportation: Proximity to destinations and transit.\n",
    "- Environmental Metrics: Assessments of emissions and vehicle usage.\n",
    "- Geographic Measurements: Geometric characterization of the land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Publicly accessibly Esri REST API Endpoint\n",
    "api_url = \"https://geodata.epa.gov/arcgis/rest/services/OA/WalkabilityIndex/MapServer/0/query\"\n",
    "\n",
    "params = {\n",
    "    \"where\": \"1=1\",  # Select all records\n",
    "    \"outFields\": \"*\",  # Retrieve all fields\n",
    "    \"f\": \"json\",  # Response format\n",
    "    \"resultRecordCount\": 10000,  # Limit to 10000 records per request to avoid rate limits\n",
    "    \"returnGeometry\": True,  # Include geographic data such as area/perimeter of census blocks\n",
    "}\n",
    "\n",
    "# Fetch the data in chunks\n",
    "def fetch_data(api_url, params):\n",
    "    offset = 0\n",
    "    all_data = []\n",
    "\n",
    "    while True:\n",
    "        params[\"resultOffset\"] = offset\n",
    "        response = requests.get(api_url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get(\"features\", [])\n",
    "            \n",
    "            if not features:\n",
    "                break  # No more records\n",
    "            \n",
    "            all_data.extend([feature[\"attributes\"] for feature in features])\n",
    "            \n",
    "            offset += len(features)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "walkability_data = fetch_data(api_url, params) # This took me about 7 minutes to run.\n",
    "\n",
    "print(walkability_data.info)\n",
    "\n",
    "# Report memory usage in MB\n",
    "memory_B = walkability_data.memory_usage(deep=True).sum()\n",
    "memory_MB = round(memory_B/1024/1024, 3)\n",
    "print(f\"The DataFrame size is {memory_MB:,} MB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
